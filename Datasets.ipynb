{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nhcnd_fV6xouD2iYENkxWT31jaIcaavH",
      "authorship_tag": "ABX9TyOjhAHjIxtU3ydLMmu5d0sR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEROYNORONHA/RetailAnalysis/blob/main/Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbRBLocZ1Y_G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import requests\n",
        "import csv\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if drive is already mounted\n",
        "if not os.path.ismount('/content/drive'):\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xIBEht_uFFl6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('amazon_products.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "vq_cv-GE-4Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['listPrice', 'isBestSeller', 'imgUrl', 'productURL', 'boughtInLastMonth'], inplace=True)\n",
        "\n",
        "df.rename(columns={\n",
        "    'asin': 'Product_ID',\n",
        "    'title': 'Product_Desc',\n",
        "    'stars': 'Product_Rating',\n",
        "    'reviews': 'Product_Reviews',\n",
        "    'price': 'Product_Price',\n",
        "    'category_id': 'Category_ID'\n",
        "}, inplace=True)"
      ],
      "metadata": {
        "id": "GX7PEnVg_Bag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['Product_Price'] != 0]"
      ],
      "metadata": {
        "id": "UfKL_dZXCBPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('products.csv', index=False)"
      ],
      "metadata": {
        "id": "KMEMgoqfCqd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('amazon_categories.csv', low_memory=False)"
      ],
      "metadata": {
        "id": "nzn_GzLp0edX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={\n",
        "    'id': 'Category_ID',\n",
        "    'category_name': 'Category_Desc'\n",
        "}, inplace=True)"
      ],
      "metadata": {
        "id": "ZnakGqwzz0BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('categories.csv', index=False)"
      ],
      "metadata": {
        "id": "6qlauZpcz0BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake domain lists\n",
        "fake_domains = [\n",
        "    'gmail.com', 'yahoo.com', 'hotmail.com', 'aol.com', 'protonmail.com',\n",
        "    'mail.com', 'icloud.com', 'outlook.com', 'live.com', 'zoho.com',\n",
        "    'gmx.com', 'fastmail.com', 'tutanota.com', 'yandex.com', 'hushmail.com',\n",
        "    'inbox.com', 'email.com', 'startmail.com', 'mailfence.com', 'runbox.com',\n",
        "    'mail.ru', 'web.de', 'laposte.net', 'bigpond.com', 'netzero.net',\n",
        "    'rediffmail.com', 'rocketmail.com', 'msn.com', 'me.com', 'usa.com',\n",
        "    'optusnet.com.au', 'btinternet.com', 'shaw.ca', 'verizon.net', 'trashmail.com',\n",
        "    'tempmail.com', '10minutemail.com', 'tiscali.co.uk', 'orange.fr', 'sympatico.ca',\n",
        "    'juno.com', 'bellsouth.net', 'freemail.hu', 'netcourrier.com', 'telus.net',\n",
        "    'uk2.net', 'cox.net', 'earthlink.net', 'safe-mail.net', 'mail2world.com'\n",
        "]\n",
        "\n",
        "companies = [\n",
        "    'techcorp', 'globex', 'dynalabs', 'futurebiz', 'infinisoft',\n",
        "    'skyforge', 'quantix', 'zenbyte', 'nexora', 'coretech',\n",
        "    'infranix', 'codevio', 'bytecraft', 'datapulse', 'metadash',\n",
        "    'infocrest', 'xentrix', 'verivue', 'tekspire', 'cyberflux',\n",
        "    'novalink', 'bluepixel', 'graygate', 'bitbridge', 'hypercore',\n",
        "    'synpulse', 'netspire', 'mindwave', 'aetherium', 'lumidyn',\n",
        "    'zenova', 'orbitex', 'sparkline', 'avionyx', 'axonify',\n",
        "    'dexatek', 'uplinx', 'corevise', 'brightleaf', 'intellisys',\n",
        "    'miraplex', 'infogenix', 'cortexon', 'cybernova', 'stackbright',\n",
        "    'pathwave', 'aegistron', 'voxelworks', 'intellivue', 'alphaqubit'\n",
        "]\n",
        "\n",
        "country_tlds = [\n",
        "    'com', 'co.uk', 'com.au', 'ca', 'co.in', 'co.nz', 'de', 'fr', 'it', 'es',\n",
        "    'nl', 'se', 'no', 'fi', 'pl', 'be', 'ch', 'at', 'pt', 'ie',\n",
        "    'cz', 'sk', 'ru', 'ua', 'ro', 'bg', 'gr', 'dk', 'hu', 'lt',\n",
        "    'lv', 'ee', 'tr', 'hk', 'sg', 'my', 'ph', 'th', 'vn', 'id',\n",
        "    'kr', 'jp', 'cn', 'za', 'ng', 'br', 'ar', 'mx', 'cl', 'pe'\n",
        "]\n",
        "\n",
        "# Email domain customizer\n",
        "def custom_domain(original_email, mode='mixed'):\n",
        "    username = original_email.split('@')[0]\n",
        "    if mode == 'free':\n",
        "        domain = random.choice(fake_domains)\n",
        "    elif mode == 'company':\n",
        "        domain = f\"{random.choice(companies)}.com\"\n",
        "    elif mode == 'country':\n",
        "        domain = f\"{random.choice(companies)}.{random.choice(country_tlds)}\"\n",
        "    else:\n",
        "        domain_type = random.choice(['free', 'company', 'country'])\n",
        "        return custom_domain(original_email, mode=domain_type)\n",
        "    return f\"{username}@{domain}\"\n",
        "\n",
        "# Fetch & create fake customers\n",
        "def get_customers(num_customers=10):\n",
        "    url = f'https://randomuser.me/api/?results={num_customers}&nat=us'\n",
        "    response = requests.get(url)\n",
        "    print(response)\n",
        "    data = response.json()['results']\n",
        "    customers = []\n",
        "    for person in data:\n",
        "        first_name = person['name']['first']\n",
        "        last_name = person['name']['last']\n",
        "        dob = datetime.strptime(person['dob']['date'], '%Y-%m-%dT%H:%M:%S.%fZ').strftime('%m/%d/%Y')\n",
        "        original_email = person['email']\n",
        "        email = custom_domain(original_email, mode='mixed')\n",
        "        gender = person['gender'].capitalize()\n",
        "        state = person['location']['state']\n",
        "        customer_type = random.choice(['Regular', 'Premium'])\n",
        "\n",
        "        customers.append([\n",
        "            first_name, last_name, dob, email, gender, state, customer_type\n",
        "        ])\n",
        "    return customers\n",
        "\n",
        "# Generate 98,765 customer rows (5000 x 19 + 3765)\n",
        "all_customers = []\n",
        "for _ in range(19):\n",
        "    all_customers.extend(get_customers(5000))\n",
        "all_customers.extend(get_customers(3765))"
      ],
      "metadata": {
        "id": "v0PfdXbU9gx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Youngest Customer\n",
        "pd.to_datetime(df['Birthday (mm/dd/yyyy)'], format='%m/%d/%Y').max()"
      ],
      "metadata": {
        "id": "-twmKZQzJpnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Oldest Customer\n",
        "pd.to_datetime(df['Birthday (mm/dd/yyyy)'], format='%m/%d/%Y').min()"
      ],
      "metadata": {
        "id": "fJnvm6gBNDI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the start and end dates\n",
        "start_date = datetime.strptime('01/01/2012', '%m/%d/%Y')\n",
        "end_date = datetime.strptime('12/31/2022', '%m/%d/%Y')\n",
        "\n",
        "# Function to generate a random date in 2012\n",
        "def random_date(start, end):\n",
        "    delta = end - start\n",
        "    random_days = random.randint(0, delta.days)\n",
        "    return (start + timedelta(days=random_days)).strftime('%m/%d/%Y')\n",
        "\n",
        "# Append a random registration date to each customer\n",
        "for customer in all_customers:\n",
        "    reg_date = random_date(start_date, end_date)\n",
        "    customer.append(reg_date)"
      ],
      "metadata": {
        "id": "RNI4smG7NhhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, customer in enumerate(all_customers, start=1):\n",
        "    customer_id = f\"{i:010d}\"  # Formats number as 10-digit string with leading zeros\n",
        "    customer.insert(0, customer_id)"
      ],
      "metadata": {
        "id": "yb5uCfBdXIe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_customers = []\n",
        "\n",
        "# with open('/content/drive/MyDrive/Colab Notebooks/customers.csv', mode='r', encoding='utf-8') as file:\n",
        "#     reader = csv.reader(file)\n",
        "#     next(reader)\n",
        "#     for row in reader:\n",
        "#         all_customers.append(row)"
      ],
      "metadata": {
        "id": "DXDt2U9OZb_0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load State to State_ID mapping from states.csv\n",
        "state_id_map = {}\n",
        "with open('states.csv', mode='r', encoding='utf-8-sig') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        state_id_map[row['State_Desc']] = row['State_ID']\n",
        "\n",
        "for customer in all_customers:\n",
        "    state_name = customer[6]\n",
        "    state_id = state_id_map.get(state_name, '')  # Default to empty if not found\n",
        "    customer.insert(7, state_id)  # Insert after the State"
      ],
      "metadata": {
        "id": "L0wuew-7Yed5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_map = {}\n",
        "\n",
        "with open('cities.csv', mode='r', encoding='utf-8-sig') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "    for row in reader:\n",
        "        state_id = row['State_ID']\n",
        "        city_id = row['City_ID']\n",
        "        if state_id not in city_map:\n",
        "            city_map[state_id] = []\n",
        "        city_map[state_id].append(city_id)\n",
        "\n",
        "updated_customers = []\n",
        "\n",
        "for customer in all_customers:\n",
        "    state_id = customer[7]\n",
        "    del customer[6]\n",
        "\n",
        "    possible_cities = city_map.get(state_id, [])\n",
        "    if possible_cities:\n",
        "        city_id = random.choice(possible_cities)\n",
        "    else:\n",
        "        city_id = None\n",
        "\n",
        "    customer.insert(6, city_id)\n",
        "\n",
        "    updated_customers.append(customer)\n",
        "\n",
        "all_customers = updated_customers"
      ],
      "metadata": {
        "id": "5-juDVHLYKL5"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_customers[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laqLiJQrgNpe",
        "outputId": "bacdb348-c1ea-4b6b-b08f-b3095dff888e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0000000006',\n",
              " 'Sara',\n",
              " 'Miller',\n",
              " '05/15/1995',\n",
              " 'sara.miller@orbitex.it',\n",
              " 'Female',\n",
              " '0066',\n",
              " '03',\n",
              " 'Regular',\n",
              " '10/24/2015']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\n",
        "    'Customer_ID', 'First_Name', 'Last_Name', 'DOB', 'Email', 'Gender',\n",
        "    'City_ID', 'State_ID', 'Customer_Type', 'Registration_Date'\n",
        "]\n",
        "# Convert your list of lists into a DataFrame\n",
        "df = pd.DataFrame(all_customers, columns=columns)\n",
        "\n",
        "# Remove duplicates based on the Email column\n",
        "df.drop_duplicates(subset='Email', keep='first', inplace=True)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv('customers.csv', index=False)"
      ],
      "metadata": {
        "id": "BdQTfsr3HeKy"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}